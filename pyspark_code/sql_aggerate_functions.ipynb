{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " Invoice ID              | 750-67-8428       \n",
      " Branch                  | A                 \n",
      " City                    | Yangon            \n",
      " Customer type           | Member            \n",
      " Gender                  | Female            \n",
      " Product line            | Health and beauty \n",
      " Unit price              | 74.69             \n",
      " Quantity                | 7                 \n",
      " Tax 5%                  | 26.1415           \n",
      " Total                   | 548.9715          \n",
      " Date                    | 1/5/2019          \n",
      " Time                    | 13:08             \n",
      " Payment                 | Ewallet           \n",
      " cogs                    | 522.83            \n",
      " gross margin percentage | 4.761904762       \n",
      " gross income            | 26.1415           \n",
      " Rating                  | 9.1               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('supermarket.csv', header=True)\n",
    "df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+-------------+------+-----------------+----------+--------+-------+--------+--------+-----+-------+------+-----------------------+------------+------+\n",
      "| Invoice_ID|Branch|  City|Customer_type|Gender|     Product_line|Unit price|Quantity| Tax 5%|   Total|    Date| Time|Payment|  cogs|gross margin percentage|gross income|Rating|\n",
      "+-----------+------+------+-------------+------+-----------------+----------+--------+-------+--------+--------+-----+-------+------+-----------------------+------------+------+\n",
      "|750-67-8428|     A|Yangon|       Member|Female|Health and beauty|     74.69|       7|26.1415|548.9715|1/5/2019|13:08|Ewallet|522.83|            4.761904762|     26.1415|   9.1|\n",
      "+-----------+------+------+-------------+------+-----------------+----------+--------+-------+--------+--------+-----+-------+------+-----------------------+------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('Product line', 'Product_line').withColumnRenamed('Customer type', 'Customer_type').withColumnRenamed('Invoice ID', 'Invoice_ID')\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('sales')\n",
    "# ANY \n",
    "# query = '''select any(City) from sales'''\n",
    "# spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|approx_count_distinct(Branch)|\n",
      "+-----------------------------+\n",
      "|                            3|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# approx_count_distinct\n",
    "query = '''select approx_count_distinct(Branch) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+\n",
      "|approx_percentile(CAST(Quantity AS DOUBLE), CAST(0.50 AS DOUBLE), 10000)|\n",
      "+------------------------------------------------------------------------+\n",
      "|                                                                     5.0|\n",
      "+------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# approx_percentile ---> calaculates the values at a given percentile of distribution of values.\n",
    "# The value found has percentile approximately equal to the given percentile\n",
    "\n",
    "query = '''select approx_percentile(Quantity, 0.50) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------+\n",
      "|        Product_line|avg(CAST(Quantity AS DOUBLE))|\n",
      "+--------------------+-----------------------------+\n",
      "|  Home and lifestyle|                      5.69375|\n",
      "| Fashion accessories|            5.067415730337078|\n",
      "|   Health and beauty|            5.618421052631579|\n",
      "|Electronic access...|            5.711764705882353|\n",
      "|  Food and beverages|            5.471264367816092|\n",
      "|   Sports and travel|            5.542168674698795|\n",
      "+--------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avg\n",
    "query =  '''select Product_line, avg(Quantity) from sales group by Product_line'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------+-----------------------------+\n",
      "|        Product_line|bit_and(CAST(Quantity AS INT))|bit_or(CAST(Quantity AS INT))|\n",
      "+--------------------+------------------------------+-----------------------------+\n",
      "|  Home and lifestyle|                             0|                           15|\n",
      "| Fashion accessories|                             0|                           15|\n",
      "|   Health and beauty|                             0|                           15|\n",
      "|Electronic access...|                             0|                           15|\n",
      "|  Food and beverages|                             0|                           15|\n",
      "|   Sports and travel|                             0|                           15|\n",
      "+--------------------+------------------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bit_and, bit_or\n",
    "\n",
    "query = '''select Product_line, bit_and(CAST(Quantity as INTEGER)), bit_or(CAST(Quantity as INTEGER)) from sales group by Product_line'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------------------------------+------+\n",
      "|bool_and((CAST(Rating AS INT) > 5))|bool_or((CAST(Rating AS INT) > 5))|Branch|\n",
      "+-----------------------------------+----------------------------------+------+\n",
      "|                              false|                              true|     B|\n",
      "|                              false|                              true|     C|\n",
      "|                              false|                              true|     A|\n",
      "+-----------------------------------+----------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bool_and, bool_or \n",
    "query = '''select bool_and(Rating > 5), bool_or(Rating > 5),Branch from sales group by Branch'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+-------------------+-------------------------+\n",
      "|collect_list(Branch)|collect_list(Product_line)|collect_set(Branch)|collect_set(Product_line)|\n",
      "+--------------------+--------------------------+-------------------+-------------------------+\n",
      "|[A, C, A, A, A, C...|      [Health and beaut...|          [C, B, A]|     [Fashion accessor...|\n",
      "+--------------------+--------------------------+-------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_list, collect_set\n",
    "query = '''select collect_list(Branch), collect_list(Product_line), collect_set(Branch), collect_set(Product_line) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+\n",
      "|corr(CAST(Quantity AS DOUBLE), CAST(Rating AS DOUBLE))|\n",
      "+------------------------------------------------------+\n",
      "|                                  -0.01581490462716...|\n",
      "+------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# corr\n",
    "query = '''select corr(Quantity,Rating) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|        Product_line|count(Product_line)|\n",
      "+--------------------+-------------------+\n",
      "|  Home and lifestyle|                160|\n",
      "| Fashion accessories|                178|\n",
      "|   Health and beauty|                152|\n",
      "|Electronic access...|                170|\n",
      "|  Food and beverages|                174|\n",
      "|   Sports and travel|                166|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count\n",
    "query = '''select Product_line, count(Product_line) from sales group by Product_line'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------+\n",
      "|count_if((CAST(Rating AS INT) > 5))|Branch|\n",
      "+-----------------------------------+------+\n",
      "|                                220|     B|\n",
      "|                                231|     C|\n",
      "|                                234|     A|\n",
      "+-----------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -- count_if\n",
    "query = '''select COUNT_IF(Rating>5), Branch from sales group by Branch'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|          covar_pop|          covar_samp|\n",
      "+-------------------+--------------------+\n",
      "|-0.0793770000000004|-0.07945645645645687|\n",
      "+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# covar_pop ---> coverience of a population\n",
    "# covar_samp ---> Returns the sample covariece \n",
    "query='''select covar_pop(Quantity, Rating) as covar_pop, covar_samp(Quantity, Rating) as covar_samp from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------------+----------------------+\n",
      "|first(Invoice_ID)|last(Invoice_ID)|first_value(Invoice_ID)|last_value(Invoice_ID)|\n",
      "+-----------------+----------------+-----------------------+----------------------+\n",
      "|      750-67-8428|     849-09-3807|            750-67-8428|           849-09-3807|\n",
      "+-----------------+----------------+-----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first, last, first_value, last_value\n",
    "query = '''select first(Invoice_ID), last(Invoice_ID), first_value(Invoice_ID), last_value(Invoice_ID) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-------------+-------------+------------------------------+\n",
      "|kurtosis(CAST(Quantity AS DOUBLE))|max(Quantity)|min(Quantity)|mean(CAST(Quantity AS DOUBLE))|\n",
      "+----------------------------------+-------------+-------------+------------------------------+\n",
      "|               -1.2154719990982275|            9|            1|                          5.51|\n",
      "+----------------------------------+-------------+-------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kurtosis, max, min, mean\n",
    "query = '''select kurtosis(Quantity), max(Quantity), min(Quantity), mean(Quantity) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+\n",
      "|max_by(Rating, Quantity)|min_by(Rating, Quantity)|\n",
      "+------------------------+------------------------+\n",
      "|                     7.4|                     4.1|\n",
      "+------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max_by ---> Returns the value of x associated with maximum value of y\n",
    "# min_by ---> Returns the value x associated with the minimum value of y\n",
    "query = '''select max_by(Rating, Quantity), min_by(Rating, Quantity) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "|per|   per_arr|          per_approx|\n",
      "+---+----------+--------------------+\n",
      "|4.0|[5.9, 6.4]|[3.0, 4.0, 4.0, 5.0]|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# percentile\n",
    "query = '''select percentile(Quantity, 0.3) as per, percentile(Rating, array(0.3,0.4)) as per_arr, percentile_approx(Quantity, array(0.3,0.35,0.4,0.5), 100) as per_approx from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----------------------------+--------------------------------+------------------------------------+-------------------------------------+\n",
      "|skewness(CAST(Quantity AS DOUBLE))|std(CAST(Quantity AS DOUBLE))|stddev(CAST(Quantity AS DOUBLE))|stddev_pop(CAST(Quantity AS DOUBLE))|stddev_samp(CAST(Quantity AS DOUBLE))|\n",
      "+----------------------------------+-----------------------------+--------------------------------+------------------------------------+-------------------------------------+\n",
      "|              0.012921628351325263|           2.9234305954556956|              2.9234305954556956|                  2.9219685145463146|                   2.9234305954556956|\n",
      "+----------------------------------+-----------------------------+--------------------------------+------------------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# skewness, std, stddev, stddev_pop, stddev_sam\n",
    "query = '''select skewness(Quantity), std(Quantity), stddev(Quantity), stddev_pop(Quantity), stddev_samp(Quantity) from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------------------+\n",
      "|      Product_line|Quantity|           per_rank|\n",
      "+------------------+--------+-------------------+\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|       1|                0.0|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "|Home and lifestyle|      10|0.08176100628930817|\n",
      "+------------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''select Product_line, Quantity,  percent_rank() over (partition by Product_line order by Quantity) as per_rank from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------+\n",
      "|      Product_line|Quantity|row_num|\n",
      "+------------------+--------+-------+\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      2|\n",
      "|Home and lifestyle|       1|      3|\n",
      "|Home and lifestyle|       1|      4|\n",
      "|Home and lifestyle|       1|      5|\n",
      "|Home and lifestyle|       1|      6|\n",
      "|Home and lifestyle|       1|      7|\n",
      "|Home and lifestyle|       1|      8|\n",
      "|Home and lifestyle|       1|      9|\n",
      "|Home and lifestyle|       1|     10|\n",
      "|Home and lifestyle|       1|     11|\n",
      "|Home and lifestyle|       1|     12|\n",
      "|Home and lifestyle|       1|     13|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     15|\n",
      "|Home and lifestyle|      10|     16|\n",
      "|Home and lifestyle|      10|     17|\n",
      "|Home and lifestyle|      10|     18|\n",
      "|Home and lifestyle|      10|     19|\n",
      "|Home and lifestyle|      10|     20|\n",
      "+------------------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''select Product_line, Quantity,  row_number() over (partition by Product_line order by Quantity) as row_num from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------+\n",
      "|      Product_line|Quantity|row_num|\n",
      "+------------------+--------+-------+\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|       1|      1|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     14|\n",
      "|Home and lifestyle|      10|     14|\n",
      "+------------------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''select Product_line, Quantity,  rank() over (partition by Product_line order by Quantity) as row_num from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------+\n",
      "|      Product_line|Quantity|cum_dist|\n",
      "+------------------+--------+--------+\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|       1| 0.08125|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "|Home and lifestyle|      10|  0.1875|\n",
      "+------------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''select Product_line, Quantity,  cume_dist() over (partition by Product_line order by Quantity) as cum_dist from sales'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
